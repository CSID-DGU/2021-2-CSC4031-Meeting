{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "요약 테스트 코드.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9TxgsZM46Yd88QyW8kz6s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2021-2-CSC4031-Meeting/blob/main/%EC%9A%94%EC%95%BD_%ED%85%8C%EC%8A%A4%ED%8A%B8_%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IS_gQY9Ca7U",
        "outputId": "4e663971-59aa-4341-8db3-74573fdbc2a8"
      },
      "source": [
        "#구글계정 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt0_h8xnCpHu",
        "outputId": "ac0234d4-33a4-4352-cb19-bdc0ac574596"
      },
      "source": [
        "!pip3 install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.8.1%2Bcpu-cp37-cp37m-linux_x86_64.whl (169.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 169.1 MB 76 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.9.1%2Bcpu-cp37-cp37m-linux_x86_64.whl (13.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.3 MB 41.9 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cpu) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cpu) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cpu) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu111\n",
            "    Uninstalling torchvision-0.10.0+cu111:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1+cpu which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1+cpu torchaudio-0.8.1 torchvision-0.9.1+cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ldxo67UC-BO",
        "outputId": "94b17f66-638a-4203-bbfd-2ef12bb9d68e"
      },
      "source": [
        "!pip install pyrouge --upgrade\n",
        "!pip install https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
        "!pip install pyrouge\n",
        "!pip show pyrouge\n",
        "!git clone https://github.com/andersjo/pyrouge.git\n",
        "from pyrouge import Rouge155\n",
        "!pyrouge_set_rouge_path 'pyrouge/tools/ROUGE-1.5.5'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyrouge\n",
            "  Downloading pyrouge-0.1.3.tar.gz (60 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▍                          | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 20 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 30 kB 30.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 40 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 51 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 60 kB 8.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191620 sha256=4ca54b5d5ae253356a9b84bc2d879fb5269ede47de8af29bd805f1288630c309\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/35/6a/ffb9a1f51b2b00fee42e7f67f5a5d8e10c67d048cda09ccd57\n",
            "Successfully built pyrouge\n",
            "Installing collected packages: pyrouge\n",
            "Successfully installed pyrouge-0.1.3\n",
            "Collecting https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "  Downloading https://github.com/bheinzerling/pyrouge/archive/master.zip\n",
            "\u001b[K     | 202 kB 7.3 MB/s\n",
            "\u001b[?25hRequirement already satisfied: pyrouge in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Name: pyrouge\n",
            "Version: 0.1.3\n",
            "Summary: A Python wrapper for the ROUGE summarization evaluation package.\n",
            "Home-page: https://github.com/noutenki/pyrouge\n",
            "Author: Benjamin Heinzerling, Anders Johannsen\n",
            "Author-email: benjamin.heinzerling@h-its.org\n",
            "License: LICENSE.txt\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "Cloning into 'pyrouge'...\n",
            "remote: Enumerating objects: 393, done.\u001b[K\n",
            "remote: Total 393 (delta 0), reused 0 (delta 0), pack-reused 393\u001b[K\n",
            "Receiving objects: 100% (393/393), 298.74 KiB | 14.94 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n",
            "2021-11-01 10:30:47,053 [MainThread  ] [INFO ]  Set ROUGE home directory to pyrouge/tools/ROUGE-1.5.5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw89ZH3ZC_4u",
        "outputId": "e306a48d-5a27-45cb-ae90-7d785105992c"
      },
      "source": [
        "\n",
        "!pip install transformers\n",
        "!pip install tensorboardX\n",
        "!pip install easydict"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 35.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 28.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.2\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (1.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZq5uZknDCpG",
        "outputId": "2a9793d6-f27c-49f4-d404-47e1266b0074"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/HaloKim/KorBertSum.git\n",
        "%cd /content/KorBertSum"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'KorBertSum'...\n",
            "remote: Enumerating objects: 11142, done.\u001b[K\n",
            "remote: Counting objects: 100% (10840/10840), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7610/7610), done.\u001b[K\n",
            "remote: Total 11142 (delta 3259), reused 10780 (delta 3220), pack-reused 302\u001b[K\n",
            "Receiving objects: 100% (11142/11142), 18.97 MiB | 16.95 MiB/s, done.\n",
            "Resolving deltas: 100% (3434/3434), done.\n",
            "/content/KorBertSum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UlxNR9pDIFV"
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('/content/KorBertSum/src')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx2TRzDyDKBN"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from models import data_loader, model_builder\n",
        "from models.model_builder import Summarizer\n",
        "from others.logging import logger, init_logger\n",
        "from models.data_loader import load_dataset\n",
        "from transformers import BertConfig, BertTokenizer\n",
        "from tensorboardX import SummaryWriter\n",
        "from models.reporter import ReportMgr\n",
        "from models.stats import Statistics\n",
        "import easydict"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiQRffBdDN8d"
      },
      "source": [
        "def _tally_parameters(model):\n",
        "    n_params = sum([p.nelement() for p in model.parameters()])\n",
        "    return n_params\n",
        "\n",
        "def build_trainer(args, device_id, model,\n",
        "                  optim):\n",
        "    \"\"\"\n",
        "    Simplify `Trainer` creation based on user `opt`s*\n",
        "    Args:\n",
        "        opt (:obj:`Namespace`): user options (usually from argument parsing)\n",
        "        model (:obj:`onmt.models.NMTModel`): the model to train\n",
        "        fields (dict): dict of fields\n",
        "        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n",
        "        data_type (str): string describing the type of data\n",
        "            e.g. \"text\", \"img\", \"audio\"\n",
        "        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n",
        "            used to save the model\n",
        "    \"\"\"\n",
        "    device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
        "\n",
        "\n",
        "    grad_accum_count = args.accum_count\n",
        "    n_gpu = args.world_size\n",
        "\n",
        "    if device_id >= 0:\n",
        "        gpu_rank = int(args.gpu_ranks[device_id])\n",
        "    else:\n",
        "        gpu_rank = 0\n",
        "        n_gpu = 0\n",
        "\n",
        "    print('gpu_rank %d' % gpu_rank)\n",
        "\n",
        "    tensorboard_log_dir = args.model_path\n",
        "\n",
        "    writer = SummaryWriter(tensorboard_log_dir, comment=\"Unmt\")\n",
        "\n",
        "    report_manager = ReportMgr(args.report_every, start_time=-1, tensorboard_writer=writer)\n",
        "\n",
        "    trainer = Trainer(args, model, optim, grad_accum_count, n_gpu, gpu_rank, report_manager)\n",
        "\n",
        "    # print(tr)\n",
        "    if (model):\n",
        "        n_params = _tally_parameters(model)\n",
        "        logger.info('* number of parameters: %d' % n_params)\n",
        "\n",
        "    return trainer\n",
        "\n",
        "\n",
        "class Trainer(object):\n",
        "    \"\"\"\n",
        "    Class that controls the training process.\n",
        "\n",
        "    Args:\n",
        "            model(:py:class:`onmt.models.model.NMTModel`): translation model\n",
        "                to train\n",
        "            train_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
        "               training loss computation\n",
        "            valid_loss(:obj:`onmt.utils.loss.LossComputeBase`):\n",
        "               training loss computation\n",
        "            optim(:obj:`onmt.utils.optimizers.Optimizer`):\n",
        "               the optimizer responsible for update\n",
        "            trunc_size(int): length of truncated back propagation through time\n",
        "            shard_size(int): compute loss in shards of this size for efficiency\n",
        "            data_type(string): type of the source input: [text|img|audio]\n",
        "            norm_method(string): normalization methods: [sents|tokens]\n",
        "            grad_accum_count(int): accumulate gradients this many times.\n",
        "            report_manager(:obj:`onmt.utils.ReportMgrBase`):\n",
        "                the object that creates reports, or None\n",
        "            model_saver(:obj:`onmt.models.ModelSaverBase`): the saver is\n",
        "                used to save a checkpoint.\n",
        "                Thus nothing will be saved if this parameter is None\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,  args, model,  optim,\n",
        "                  grad_accum_count=1, n_gpu=1, gpu_rank=1,\n",
        "                  report_manager=None):\n",
        "        # Basic attributes.\n",
        "        self.args = args\n",
        "        self.save_checkpoint_steps = args.save_checkpoint_steps\n",
        "        self.model = model\n",
        "        self.optim = optim\n",
        "        self.grad_accum_count = grad_accum_count\n",
        "        self.n_gpu = n_gpu\n",
        "        self.gpu_rank = gpu_rank\n",
        "        self.report_manager = report_manager\n",
        "\n",
        "        self.loss = torch.nn.BCELoss(reduction='none')\n",
        "        assert grad_accum_count > 0\n",
        "        # Set model in training mode.\n",
        "        if (model):\n",
        "            self.model.train()\n",
        "\n",
        "    def summ(self, test_iter, step, cal_lead=False, cal_oracle=False):\n",
        "      \"\"\" Validate model.\n",
        "          valid_iter: validate data iterator\n",
        "      Returns:\n",
        "          :obj:`nmt.Statistics`: validation loss statistics\n",
        "      \"\"\"\n",
        "      # Set model in validating mode.\n",
        "      def _get_ngrams(n, text):\n",
        "          ngram_set = set()\n",
        "          text_length = len(text)\n",
        "          max_index_ngram_start = text_length - n\n",
        "          for i in range(max_index_ngram_start + 1):\n",
        "              ngram_set.add(tuple(text[i:i + n]))\n",
        "          return ngram_set\n",
        "\n",
        "      def _block_tri(c, p):\n",
        "          tri_c = _get_ngrams(3, c.split())\n",
        "          for s in p:\n",
        "              tri_s = _get_ngrams(3, s.split())\n",
        "              if len(tri_c.intersection(tri_s))>0:\n",
        "                  return True\n",
        "          return False\n",
        "\n",
        "      if (not cal_lead and not cal_oracle):\n",
        "          self.model.eval()\n",
        "      stats = Statistics()\n",
        "\n",
        "      with torch.no_grad():\n",
        "          for batch in test_iter:\n",
        "              src = batch.src\n",
        "              labels = batch.labels\n",
        "              segs = batch.segs\n",
        "              clss = batch.clss\n",
        "              mask = batch.mask\n",
        "              mask_cls = batch.mask_cls\n",
        "\n",
        "              if (cal_lead):\n",
        "                  selected_ids = [list(range(batch.clss.size(1)))] * batch.batch_size\n",
        "              elif (cal_oracle):\n",
        "                  selected_ids = [[j for j in range(batch.clss.size(1)) if labels[i][j] == 1] for i in\n",
        "                                  range(batch.batch_size)]\n",
        "              else:\n",
        "                  sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
        "                  sent_scores = sent_scores + mask.float()\n",
        "                  sent_scores = sent_scores.cpu().data.numpy()\n",
        "                  selected_ids = np.argsort(-sent_scores, 1)\n",
        "      return selected_ids\n",
        "\n",
        "\n",
        "\n",
        "    def _gradient_accumulation(self, true_batchs, normalization, total_stats,\n",
        "                               report_stats):\n",
        "        if self.grad_accum_count > 1:\n",
        "            self.model.zero_grad()\n",
        "\n",
        "        for batch in true_batchs:\n",
        "            if self.grad_accum_count == 1:\n",
        "                self.model.zero_grad()\n",
        "\n",
        "            src = batch.src\n",
        "            labels = batch.labels\n",
        "            segs = batch.segs\n",
        "            clss = batch.clss\n",
        "            mask = batch.mask\n",
        "            mask_cls = batch.mask_cls\n",
        "\n",
        "            sent_scores, mask = self.model(src, segs, clss, mask, mask_cls)\n",
        "\n",
        "            loss = self.loss(sent_scores, labels.float())\n",
        "            loss = (loss*mask.float()).sum()\n",
        "            (loss/loss.numel()).backward()\n",
        "            # loss.div(float(normalization)).backward()\n",
        "\n",
        "            batch_stats = Statistics(float(loss.cpu().data.numpy()), normalization)\n",
        "\n",
        "\n",
        "            total_stats.update(batch_stats)\n",
        "            report_stats.update(batch_stats)\n",
        "\n",
        "            # 4. Update the parameters and statistics.\n",
        "            if self.grad_accum_count == 1:\n",
        "                # Multi GPU gradient gather\n",
        "                if self.n_gpu > 1:\n",
        "                    grads = [p.grad.data for p in self.model.parameters()\n",
        "                             if p.requires_grad\n",
        "                             and p.grad is not None]\n",
        "                    distributed.all_reduce_and_rescale_tensors(\n",
        "                        grads, float(1))\n",
        "                self.optim.step()\n",
        "\n",
        "        # in case of multi step gradient accumulation,\n",
        "        # update only after accum batches\n",
        "        if self.grad_accum_count > 1:\n",
        "            if self.n_gpu > 1:\n",
        "                grads = [p.grad.data for p in self.model.parameters()\n",
        "                         if p.requires_grad\n",
        "                         and p.grad is not None]\n",
        "                distributed.all_reduce_and_rescale_tensors(\n",
        "                    grads, float(1))\n",
        "            self.optim.step()\n",
        "\n",
        "    def _save(self, step):\n",
        "        real_model = self.model\n",
        "        # real_generator = (self.generator.module\n",
        "        #                   if isinstance(self.generator, torch.nn.DataParallel)\n",
        "        #                   else self.generator)\n",
        "\n",
        "        model_state_dict = real_model.state_dict()\n",
        "        # generator_state_dict = real_generator.state_dict()\n",
        "        checkpoint = {\n",
        "            'model': model_state_dict,\n",
        "            # 'generator': generator_state_dict,\n",
        "            'opt': self.args,\n",
        "            'optim': self.optim,\n",
        "        }\n",
        "        checkpoint_path = os.path.join(self.args.model_path, 'model_step_%d.pt' % step)\n",
        "        logger.info(\"Saving checkpoint %s\" % checkpoint_path)\n",
        "        # checkpoint_path = '%s_step_%d.pt' % (FLAGS.model_path, step)\n",
        "        if (not os.path.exists(checkpoint_path)):\n",
        "            torch.save(checkpoint, checkpoint_path)\n",
        "            return checkpoint, checkpoint_path\n",
        "\n",
        "    def _start_report_manager(self, start_time=None):\n",
        "        \"\"\"\n",
        "        Simple function to start report manager (if any)\n",
        "        \"\"\"\n",
        "        if self.report_manager is not None:\n",
        "            if start_time is None:\n",
        "                self.report_manager.start()\n",
        "            else:\n",
        "                self.report_manager.start_time = start_time\n",
        "\n",
        "    def _maybe_gather_stats(self, stat):\n",
        "        \"\"\"\n",
        "        Gather statistics in multi-processes cases\n",
        "\n",
        "        Args:\n",
        "            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n",
        "                or None (it returns None in this case)\n",
        "\n",
        "        Returns:\n",
        "            stat: the updated (or unchanged) stat object\n",
        "        \"\"\"\n",
        "        if stat is not None and self.n_gpu > 1:\n",
        "            return Statistics.all_gather_stats(stat)\n",
        "        return stat\n",
        "\n",
        "    def _maybe_report_training(self, step, num_steps, learning_rate,\n",
        "                               report_stats):\n",
        "        \"\"\"\n",
        "        Simple function to report training stats (if report_manager is set)\n",
        "        see `onmt.utils.ReportManagerBase.report_training` for doc\n",
        "        \"\"\"\n",
        "        if self.report_manager is not None:\n",
        "            return self.report_manager.report_training(\n",
        "                step, num_steps, learning_rate, report_stats,\n",
        "                multigpu=self.n_gpu > 1)\n",
        "\n",
        "    def _report_step(self, learning_rate, step, train_stats=None,\n",
        "                     valid_stats=None):\n",
        "        \"\"\"\n",
        "        Simple function to report stats (if report_manager is set)\n",
        "        see `onmt.utils.ReportManagerBase.report_step` for doc\n",
        "        \"\"\"\n",
        "        if self.report_manager is not None:\n",
        "            return self.report_manager.report_step(\n",
        "                learning_rate, step, train_stats=train_stats,\n",
        "                valid_stats=valid_stats)\n",
        "\n",
        "    def _maybe_save(self, step):\n",
        "        \"\"\"\n",
        "        Save the model if a model saver is set\n",
        "        \"\"\"\n",
        "        if self.model_saver is not None:\n",
        "            self.model_saver.maybe_save(step)\n",
        "\n",
        "class BertData():\n",
        "    def __init__(self):\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "        self.sep_vid = self.tokenizer.vocab['[SEP]']\n",
        "        self.cls_vid = self.tokenizer.vocab['[CLS]']\n",
        "        self.pad_vid = self.tokenizer.vocab['[PAD]']\n",
        "\n",
        "    def preprocess(self, src):\n",
        "\n",
        "        if (len(src) == 0):\n",
        "            return None\n",
        "\n",
        "        original_src_txt = [' '.join(s) for s in src]\n",
        "        idxs = [i for i, s in enumerate(src) if (len(s) > 1)]\n",
        "\n",
        "        src = [src[i][:2000] for i in idxs]\n",
        "        src = src[:1000]\n",
        "\n",
        "        if (len(src) < 3):\n",
        "            return None\n",
        "\n",
        "        src_txt = [' '.join(sent) for sent in src]\n",
        "        text = ' [SEP] [CLS] '.join(src_txt)\n",
        "        src_subtokens = self.tokenizer.tokenize(text)\n",
        "        src_subtokens = src_subtokens[:510]\n",
        "        src_subtokens = ['[CLS]'] + src_subtokens + ['[SEP]']\n",
        "\n",
        "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
        "        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n",
        "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
        "        segments_ids = []\n",
        "        for i, s in enumerate(segs):\n",
        "            if (i % 2 == 0):\n",
        "                segments_ids += s * [0]\n",
        "            else:\n",
        "                segments_ids += s * [1]\n",
        "        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n",
        "        labels = None\n",
        "        src_txt = [original_src_txt[i] for i in idxs]\n",
        "        tgt_txt = None\n",
        "        return src_subtoken_idxs, labels, segments_ids, cls_ids, src_txt, tgt_txt\n",
        "\n",
        "def _lazy_dataset_loader(pt_file):\n",
        "  yield  pt_file"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzBwPfFQDSxX"
      },
      "source": [
        "args = easydict.EasyDict({\n",
        "    \"encoder\":'classifier',\n",
        "    \"mode\":'test',\n",
        "    \"bert_data_path\":'/content/KorBertSum/bert_data/korean',\n",
        "    \"model_path\":'./models/bert_classifier',\n",
        "    \"result_path\":'./results',\n",
        "    \"temp_dir\":'./temp',\n",
        "    \"batch_size\":1000,\n",
        "    \"use_interval\":True,\n",
        "    \"hidden_size\":128,\n",
        "    \"ff_size\":512,\n",
        "    \"heads\":4,\n",
        "    \"inter_layers\":2,\n",
        "    \"rnn_size\":512,\n",
        "    \"param_init\":0,\n",
        "    \"param_init_glorot\":True,\n",
        "    \"dropout\":0.1,\n",
        "    \"optim\":'adam',\n",
        "    \"lr\":2e-3,\n",
        "    \"report_every\":1,\n",
        "    \"save_checkpoint_steps\":5,\n",
        "    \"block_trigram\":True,\n",
        "    \"recall_eval\":False,\n",
        "    \n",
        "    \"accum_count\":1,\n",
        "    \"world_size\":1,\n",
        "    \"visible_gpus\":'-1',\n",
        "    \"gpu_ranks\":'0',\n",
        "    \"log_file\":'/content/KorBertSum/logs/log.log',\n",
        "    \"test_from\":'/content/gdrive/MyDrive/<융캡> 회의중 드라이브/문서요약/model_step_24000.pt의 사본'\n",
        "})\n",
        "model_flags = ['hidden_size', 'ff_size', 'heads', 'inter_layers','encoder','ff_actv', 'use_interval','rnn_size']"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kovkqfz3DUE2"
      },
      "source": [
        "def test(args, input_list, device_id, pt, step):\n",
        "  init_logger(args.log_file)\n",
        "  device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
        "  device_id = 0 if device == \"cuda\" else -1\n",
        "\n",
        "  cp = args.test_from\n",
        "  try:\n",
        "    step = int(cp.split('.')[-2].split('_')[-1])\n",
        "  except:\n",
        "    step = 0\n",
        "\n",
        "  device = \"cpu\" if args.visible_gpus == '-1' else \"cuda\"\n",
        "  if (pt != ''):\n",
        "      test_from = pt\n",
        "  else:\n",
        "      test_from = args.test_from\n",
        "  logger.info('Loading checkpoint from %s' % test_from)\n",
        "  checkpoint = torch.load(test_from, map_location=lambda storage, loc: storage)\n",
        "  opt = vars(checkpoint['opt'])\n",
        "  for k in opt.keys():\n",
        "      if (k in model_flags):\n",
        "        setattr(args, k, opt[k])\n",
        "\n",
        "  config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
        "  model = Summarizer(args, device, load_pretrained_bert=False, bert_config = config)\n",
        "  model.load_cp(checkpoint)\n",
        "  model.eval()\n",
        "\n",
        "  test_iter = data_loader.Dataloader(args, _lazy_dataset_loader(input_list),\n",
        "                                args.batch_size, device,\n",
        "                                shuffle=False, is_test=True)\n",
        "  trainer = build_trainer(args, device_id, model, None)\n",
        "  result = trainer.summ(test_iter,step)\n",
        "  return result, input_list\n",
        "\n",
        "args.gpu_ranks = [int(i) for i in args.gpu_ranks.split(',')]\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.visible_gpus"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtu6PcpuDVRm"
      },
      "source": [
        "def txt2input(text):\n",
        "  data = list(filter(None, text.split('\\n')))\n",
        "  bertdata = BertData()\n",
        "  txt_data = bertdata.preprocess(data)\n",
        "  data_dict = {\"src\":txt_data[0],\n",
        "               \"labels\":[0,1,2],\n",
        "               \"segs\":txt_data[2],\n",
        "               \"clss\":txt_data[3],\n",
        "               \"src_txt\":txt_data[4],\n",
        "               \"tgt_txt\":None}\n",
        "  input_data = []\n",
        "  input_data.append(data_dict)\n",
        "  return input_data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czU8kl-LDWbO"
      },
      "source": [
        "text = '''\n",
        "임진년의 외인들이 난을 버렸다 그래서 임진왜란 인데요.\n",
        "자 지도 한번 보실께요 자 중국이 있고 우리나라가 있고 이렇게 일본이 펼쳐집니다.\n",
        "여기는 일본을 주목 하셔야 되는데요.\n",
        "백년동안 자기들끼리 치고받고 있어요 이걸 전국시대 라고 합니다.\n",
        "당시 도요토미 히데요시가 조총으로 통일합니다.\n",
        "통일을 했는데 문제는 너무 불안정한 통일 이였어요.\n",
        "내부적인 결속이 필요했습니다.\n",
        "자 또한 뭐냐 자 무사들은 어떡할 거에요.\n",
        "무사 라는 건 전쟁통에 능력을 발휘하는 사람들인데 이 평화의 시기에  뭐 하는 일 없이 백수로 죽으란 얘기 아닙니까 \n",
        "안되겠다 이들의 에너지를 표출할 수 있는 분출구를 찾아야겠다는 생각을 합니다.\n",
        "자 이런 상황에서 일본이 드디어 우리나라를 침공을 한 겁니다\n",
        "자 부산으로 바로 쳐 들어 온거죠\n",
        "아 그들의 생각은 뭐냐 조선에서 힘 빼겠다고 그런거 필요없어요\n",
        "속도전으로 재빠르게 서울까지 치고 올라가서 임금을 인질로 잡는 겁니다\n",
        "그래서 그를 볼모 삼아 서 군사들을 모아 그리고 불량배를 모아 그래가지고 총알받이로 조선인들의 앞장 세우고\n",
        "이제 중국도 쳐들어 가려고 했던 거죠 그런데 세상에 우리 선조가 상상도 하지 못한 업적을 남기시죠\n",
        "한양을 버리고 의주로 도망을 갑니다.\n",
        "서울에 딱 왔더니 임금이 없는 거에요.\n",
        "일본의 무사들은요 아무리 작은 성의 성주라도 성을 버리고 도망가는 일이 없습니다\n",
        "배가르고 죽거나 아니면 딱 항복해요.\n",
        "그런데 세상에 성주도 아니고 나라의 임금 이라는 사람이 수도로 버리고 도망을 가니까. \n",
        "일본인들은 어 이거 어떡하지 우리 어떻게 해야 돼 그러면서 서울에서 추첨 평양 에서 주춤 주춤 시간을 보내고 있었던 거죠.\n",
        "이 시간이 이순신 한텐  골든타임 이었습니다.\n",
        "재 전열을 하고 일본을 칠 수 있는 시간을 벌어 준 겁니다.\n",
        "아 거기서 일본의 2차 목표는 뭐냐면 자 육군은 1차로 치고 올라가죠.\n",
        "그리고 2차 부대는 남해안을  돌아서 이렇게 서해안으로 상륙을합니다. \n",
        "일본 의 1차 부대에게 이제 무기와 식량을 공급하겠다.\n",
        "이것이 그들의 계획이었는데 이건 뭐 이 이순신 장군께서 족족 끊어버렸어요.\n",
        "해전에서 아예 그냥 씨를 말려 버립니다.\n",
        "일본인들은 배고프잖아요 무기도 없잖아요 힘이 빠집니다.\n",
        "그래서 1년만에 군대를 철수하게 되니 이것이 임진왜란이 됩니다.\n",
        "'''"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q168yoqvDXnm",
        "outputId": "28563bd2-e673-4438-ace0-4d1878369645"
      },
      "source": [
        "input_data = txt2input(text)\n",
        "sum_list = test(args, input_data, -1, '', None)\n",
        "sum_list[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2021-11-01 10:33:12,626 INFO] Loading checkpoint from /content/gdrive/MyDrive/<융캡> 회의중 드라이브/문서요약/model_step_24000.pt의 사본\n",
            "[2021-11-01 10:33:36,086 INFO] * number of parameters: 177854209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu_rank 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9, 16,  2, 14, 12, 11, 10, 17, 18,  3,  5, 13, 15,  1,  7,  4,\n",
              "         8,  0,  6]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99NrBz0ZDY02",
        "outputId": "75749538-f53f-40c6-d563-552c499571ea"
      },
      "source": [
        "[list(filter(None, text.split('\\n')))[i] for i in sum_list[0][0][:3]]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['안되겠다 이들의 에너지를 표출할 수 있는 분출구를 찾아야겠다는 생각을 합니다.',\n",
              " '한양을 버리고 의주로 도망을 갑니다.',\n",
              " '여기는 일본을 주목 하셔야 되는데요.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}